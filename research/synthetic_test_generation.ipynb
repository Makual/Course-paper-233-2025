{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac9cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69261/3365363725.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import Dict, List\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from utils import fetch_random_news\n",
    "from multiprocessing import Pool\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd4171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PG_DSN = (\n",
    "    f\"postgresql://{os.getenv('PG_USER')}:\"\n",
    "    f\"{os.getenv('PG_PASS')}@\"\n",
    "    f\"{os.getenv('PG_HOST')}:\"\n",
    "    f\"{os.getenv('PG_PORT')}/\"\n",
    "    f\"{os.getenv('PG_DB')}\"\n",
    ")\n",
    "OPENROUTER_KEY = os.getenv('OPENROUTER_KEY')\n",
    "engine = create_engine(PG_DSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12bbb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_KEYS = {\"easy\", \"medium\", \"hard\"}\n",
    "\n",
    "def parse_gpt_output(raw: str, *, article_id: str = \"\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Преобразует сырой текст от gpt.generate_for_article\n",
    "    в словарь {\"easy\": \"...\", \"medium\": \"...\", \"hard\": \"...\"}.\n",
    "    • Игнорирует пустые строки и строки без “:” или “-”/“–”/“—”.\n",
    "    • Ключи чувствительны к регистру, приводятся к нижнему.\n",
    "    • Если ключ отсутствует, возвращается пустая строка.\n",
    "    \"\"\"\n",
    "    out = {k: \"\" for k in EXPECTED_KEYS}\n",
    "\n",
    "    print(raw)\n",
    "\n",
    "    for line in raw.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        # Попробуем найти “ключ : значение” или “ключ - значение” и т.д.\n",
    "        m = re.match(r\"^\\s*([\\w]+)\\s*[:\\-–—]\\s*(.+)$\", line)\n",
    "        if not m:\n",
    "            # при желании можно раскомментировать для диагностики\n",
    "            # print(f\"[Warn] article_id={article_id} → could not parse line: {line!r}\")\n",
    "            continue\n",
    "\n",
    "        k, v = m.group(1).lower(), m.group(2).strip()\n",
    "        if k in EXPECTED_KEYS:\n",
    "            out[k] = v\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTSynthesizer:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "    def _gpt_query(self, system_prompt: str, prompt: str) -> str:\n",
    "        messages: List[Dict[str, str]] = []\n",
    "        if system_prompt:\n",
    "            messages.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Всегда отвечай на русском языке. \" + system_prompt\n",
    "            })\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": \"google/gemma-2-9b-it\",\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0,\n",
    "            \"max_tokens\": 512,\n",
    "            \"seed\": 42,\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    def generate_for_article(self, title: str, anons: str, body: str, *, article_id: str = \"\") -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Для переданной статьи (title, anons, body) формирует 3 поисковых запроса\n",
    "        с разными уровнями сложности: лёгкий, средний, сложный.\n",
    "        Возвращает словарь {\"easy\": ..., \"medium\": ..., \"hard\": ...}.\n",
    "        \"\"\"\n",
    "        snippet = body[:200].replace(\"\\n\", \" \")\n",
    "        full_context = f\"Заголовок: {title}\\nАнонс: {anons or ''}\\nТело (фрагмент): {snippet}...\"\n",
    "        system_prompt = (\n",
    "            \"Ты генерируешь три реалистичных поисковых запроса человека в поисковике разного уровня сложности, \"\n",
    "            \"чтобы найти именно эту новость на новостном портале. \"\n",
    "            \"Первый запрос — максимально буквальный, в точности, как в новости\"\n",
    "            \"Второй — чуть более обобщённый (с синонимами). Как бы мог сформулировать эту новость человек\"\n",
    "            \"Третий — максимально абстрактный, где используются контекстные формулировки и косвенные признаки, \"\n",
    "            \"возможны реалестичные опечатки, чтобы тестировать поисковую систему по новостям\"\n",
    "        )\n",
    "        prompt = (\n",
    "            f\"{full_context}\\n\\n\"\n",
    "            \"Сгенерируй три отдельных строки, помеченные как:\\n\"\n",
    "            \"easy: <здесь>\\n\"\n",
    "            \"medium: <здесь>\\n\"\n",
    "            \"hard: <здесь>\"\n",
    "        )\n",
    "\n",
    "        raw = self._gpt_query(system_prompt, prompt)\n",
    "\n",
    "        parsed = parse_gpt_output(raw, article_id=article_id)\n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9afa0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = fetch_random_news(limit=1, sample_pct=1.0)\n",
    "gpt = GPTSynthesizer(api_key=OPENROUTER_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52545061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_row_tuple(args):\n",
    "    art_id, title, anons, body = args\n",
    "    try:\n",
    "        gens = gpt.generate_for_article(title, anons, body, article_id=art_id)\n",
    "        # Если нужны дополнительные проверки:\n",
    "        # if not all(k in gens for k in (\"easy\", \"medium\", \"hard\")):\n",
    "        #     raise ValueError(f\"Missing keys in gens for article {art_id}: {gens.keys()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] article_id={art_id} → {type(e).__name__}: {e}\")\n",
    "        gens = {\"easy\": \"\", \"medium\": \"\", \"hard\": \"\"}\n",
    "    return art_id, gens\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Основная функция для генерации в несколько процессов\n",
    "# -----------------------------\n",
    "def generate_synthetic_mp(df, num_workers=None, chunksize=10):\n",
    "    \"\"\"\n",
    "    Обрабатывает каждую строку df параллельно, используя multiprocessing.Pool.\n",
    "    Возвращает список кортежей: (article_id, difficulty, generated_text).\n",
    "    \"\"\"\n",
    "    arg_list = [\n",
    "        (row[\"id\"], row[\"title\"], row[\"anons\"], row[\"body\"])\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    synthetic = []\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        for art_id, gens in tqdm(\n",
    "            pool.imap_unordered(_process_row_tuple, arg_list, chunksize=chunksize),\n",
    "            total=len(arg_list),\n",
    "            desc=\"Generating synthetic queries\",\n",
    "        ):\n",
    "            synthetic.append((art_id, \"easy\",   gens.get(\"easy\", \"\")))\n",
    "            synthetic.append((art_id, \"medium\", gens.get(\"medium\", \"\")))\n",
    "            synthetic.append((art_id, \"hard\",   gens.get(\"hard\", \"\")))\n",
    "\n",
    "    return synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2808ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic queries:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy: пропавшая подлодка аргентина 44 человека\n",
      "medium: аргентинская подлодка превышен лимит экипажа\n",
      "hard:  подлодка аргентина родственники погибших больше людей чем положено \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic queries: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "synthetic_queries = generate_synthetic_mp(df_sample, num_workers=None, chunksize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c2d0bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('73af9a711234d8515b80baae8e2d1246',\n",
       "  'easy',\n",
       "  'пропавшая подлодка аргентина 44 человека'),\n",
       " ('73af9a711234d8515b80baae8e2d1246',\n",
       "  'medium',\n",
       "  'аргентинская подлодка превышен лимит экипажа'),\n",
       " ('73af9a711234d8515b80baae8e2d1246',\n",
       "  'hard',\n",
       "  'подлодка аргентина родственники погибших больше людей чем положено')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "076f406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:00<00:00, 2678868.24it/s]\n"
     ]
    }
   ],
   "source": [
    "df_synth = pd.DataFrame(synthetic_queries, columns=[\"article_id\", \"difficulty\", \"query\"])\n",
    "queries_gt: Dict[str, List[str]] = {}\n",
    "for art_id, difficulty, q in tqdm(synthetic_queries):\n",
    "    queries_gt[q] = [art_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de85308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synth.to_csv(\"synthetic_queries_random.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1764372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
